
# 1. Пример запуска контейнера из образа hello-world (Образ скачается, если его нет)
docker-run-hello-world:
	docker run --name hello-container hello-world

# docker — вызов докер-клиента.

# run — команда для докер-клиента: «запусти контейнер».

# --name hello-container — параметр для команды run: «присвой запущенному 
# контейнеру имя hello-container». 
# У каждого контейнера должно быть уникальное имя. 
# Если его не указать при запуске, контейнеру будет присвоено случайное имя, 
# вроде такого: 94f92052f55f. 

# hello-world — имя образа, из которого должен быть запущен контейнер.

# Каждому образу, сохранённому на Docker Hub, присвоено уникальное имя. 
# Образ hello-world есть на Docker Hub, докер скачает образ на ваш компьютер

# 2.1 порты контейнера (docker run -p порт_хоста:порт_контейнера)
nginx:
	docker run -p 80:80 --name nginx-container nginx 

# Контейнер считает себя полноценным компьютером, и у него тоже есть порты. 
# Но у контейнера свой порт 80, у хоста — свой. 
# Запрос пришёл на 80-й порт хоста, а Nginx ждёт запроса на 80-й порт контейнера.
# А никакой связи между этими портами нет: 
# порты контейнеров по умолчанию не связаны с портами хоста.

# Задача в том, чтобы передать запрос, полученный хостом, на 80-й порт контейнера. 
# Для этого нужно связать порт контейнера с портом хоста. 
# Docker это умеет: связь портов можно указать при запуске контейнера. 
# У команды docker run есть флаг --publish (или сокращённо -p) — «назначить порт публичным»; 
# после флага указывается порт хоста и связанный с ним порт контейнера:
# $ docker run -p порт_хоста:порт_контейнера

# 2.2 перед удалением остановить контейнер
stop-nginx1:
	docker container stop nginx-container

# 2.3 удалить контейнер
rm-nginx:
	docker container rm nginx-container

# 2.4 переадресация
nginx-2:
	docker run -p 8080:80 --name nginx-container nginx 

# 3.1 команда для просмотра списка запущенных контейнеров (cтарый вариант docker ps)
container-ls:
	docker container ls 

# список всех контейнеров
container-ls-a:
	docker container ls -a 

# 4. запуск остановелнного контейнера (краткий вариант/старый)
start-nginx:
	docker start nginx-container

# При старте остановленного контейнера не понадобилось указывать связь портов: 
# остановленный контейнер сохраняет все свои настройки

# 4.1 запуск остановелнного контейнера 
start-nginx-2:
	docker container start nginx-container 


# Команда 
# start 
# запускает существующий остановленный контейнер, 
# а команда 
# run 
# создаёт новый контейнер из заданного образа. Не путай!!

# 4.1 остановка контейнера (краткий вариант/старый)
stop-nginx3:
	docker stop nginx-container

# 5. войти в контейнер
# docker exec -it <CONTAINER ID> any_instruction 
exec-it-nginx:
	docker exec -it nginx-container bash

# exec — запустит команду внутри контейнера.
# -it — аргумент для выполнения команды в контейнере в интерактивном режиме. 
# Этот аргумент нужен, если планируется не просто выполнить команду в контейнере, 
# но и получить ответ от внутреннего терминала контейнера. 
# С аргументом -it все команды и ответы контейнера будут работать так, 
# будто вы запустили команду не в контейнере, а в терминале своей операционной системы.
# any_instruction — команда, которая будет выполнена в терминале контейнера.

# (или нажмите Ctrl+D для выхода)

# 6. исполнить команду в контейнере
exec-nginx:
	docker exec nginx-container touch /my-file

# 7. списока образов
image-ls: 
	docker image ls 

################################################################################
# Dockerfile — это файл с инструкциями для создания образа.

### 1. Докерфайл. 

# В докерфайле разработчик перечисляет, что должно быть сделано для сборки образа: 
#  - под какой операционной системой должен работать контейнер, 
#  - какие пакеты этой ОС нужны для работы приложения, 
#  - какие файлы надо перенести в образ. 
# Dockerfile, как правило, создают в директории того приложения, 
# которое будет упаковано в образ.

# В докерфайле описываются и операции, 
# которые должны быть выполнены при старте контейнера: 
# например, для старта Django-проекта 
# в режиме разработки надо выполнить команду python manage.py runserver. 
# Эта команда тоже указывается в докерфайле.

# В директории backend/ проекта Taski создайте файл под названием Dockerfile. 
# Название должно начинаться с большой буквы; расширение указывать не нужно.
# (см докер файл)

### 2. base image

# Любой новый образ собирается на основе базового слоя (base image). 
# Базовый слой — это образ, который указывает, 
# какая операционная система требуется для работы контейнера. 

# Базовый слой может включать и дополнительные пакеты для операционной системы 
# (например, образ python:3.9 содержит пакет с интерпретатором Python). 
# Образы для базовых слоёв можно найти на Docker Hub.

#  Базовый слой указывается в инструкции FROM.
# FROM <image>:<tag>
# <image> — имя базового образа, например, python.
# <tag> — необязательный параметр, указывает конкретную версию образа.

# Если в Dockerfile не указать версию базового образа, 
# то будет установлена версия :latest

# Другие версии базовых образов Python — buster, bullseye, alpine. 
# Эти версии различаются размером и скоростью сборки.

### 3. WORKDIR

# Инструкция WORKDIR позволяет переходить 
# из директории в директорию образа и устанавливает, 
# в какой директории будут выполняться команды, 
# описанные в Dockerfile, — это сходно с выполнением команды cd в терминале.

# WORKDIR <путь-к-директории-внутри-контейнера>
# # Тут можно совершить какие-то действия в директории — 
# # например, выполнить команду в терминале:
# RUN mkdir new_folder
# # Потом можно перейти в другую директорию:
# WORKDIR <путь-к-другой-директории-внутри-контейнера>
# # ...и выполнить какие-то действия в ней. 

# Если директории, указанной в инструкции WORKDIR, 
# не существует, эта директория будет создана.

# В WORKDIR можно указывать относительный путь, он будет начинаться с текущей директории:

# # Это абсолютный путь, он начинается со слеша 
# # и отсчитывается от корневой директории:
# WORKDIR /workdir 
# # Это относительный путь — он без слеша в начале и отсчитывается от той директории,
# # в которой мы сейчас:
# WORKDIR project
# WORKDIR app
# RUN pwd 
# # Команда pwd выведет адрес /workdir/project/app 

# В инструкции WORKDIR лучше указывать абсолютный 
# путь до директории — иначе можно случайно назначить рабочей директорией неизвестную подпапку:
# WORKDIR /workdir
# WORKDIR /project
# WORKDIR /app
# RUN pwd
# # Выведет адрес директории /app в корне контейнера. 

### 4. Инструкция COPY

# Эта инструкция — команда на копирование файлов и директорий 
# из заданной директории компьютера в указанную директорию образа. 
# Путь на локальном компьютере отсчитывается от директории, где хранится докерфайл.

# COPY <локальный_файл_или_директория> <путь_внутри_образа>
# # Альтернативный вариант записи:
# COPY ["<локальный_файл_или_директория>", "<путь_внутри_образа>"] 

# в примере (см Dockerfile)
# Скопировать файл requirements.txt из директории, где хранится Dockerfile,
# в текущую директорию образа.
# COPY requirements.txt . 

# Второй раз инструкция COPY применена для копирования содержимого 
# локальной директории компьютера в текущую директорию образа:
# Скопировать всё содержимое директории, где хранится Dockerfile,
# в текущую директорию образа.
# Точка в обоих случаях обозначает текущую директорию:
# первая на хосте, вторая — внутри образа
# COPY . . 

# Если целевой директории для копирования не существует — инструкция COPY создаст её!
# Скопировать всё содержимое директории, где хранится Dockerfile,
# в директорию /nonexistent образа.
# COPY . /nonexistent
# Если в образе не было директории /nonexistent, она будет создана. 

### 5. Файл .dockerignore

# Некоторые файлы и директории не должны попасть в образ: 
# они там не нужны, при копировании надо исключить их. 
# Такие исключения можно перечислить в файле .dockerignore; 
# он должен располагаться в той же директории, что и Dockerfile. 
# Принцип работы файла .dockerignore такой же, как у .gitignore.

# # .dockerignore
# venv
# .git
# db.sqlite3 
# .env
# .idea
# .vscode

### 6. Инструкция RUN

# Эта инструкция выполняет команды терминала внутри образа так, 
# как если бы эти команды выполнял разработчик. 
# RUN <команда> 

# В докерфайле для Taski инструкция RUN запускает внутри образа команду 
# для установки зависимостей:

# Если не использовать параметр --no-cache-dir, 
# то pip сохранит в служебной директории (прямо в образе) копии пакетов,
# а это будет лишним грузом.
# RUN pip install -r /app/requirements.txt --no-cache-dir 

# В образе нет нужной утилиты? Ок, установим её!
# Обратите внимание: sudo тут не нужен, так как внутри контейнера
# все команды выполняются от имени root
# RUN apt -y install python3-pip
# Вот теперь можно обратиться к pip...
# RUN pip install -r /app/requirements.txt --no-cache-dir
# ...и команда выполнится без ошибок. 

### 7. Инструкция CMD

# Инструкция CMD указывает, какую команду нужно выполнить при запуске контейнера, 
# — в отличие от инструкции RUN, которая выполнит команду при сборке образа.

# У инструкции CMD есть три особенности:
# в Dockerfile срабатывает только одна инструкция CMD. 
# Если этих инструкций несколько, выполнится только та, что записана последней;
# параметры инструкции CMD указываются в виде JSON-массива,
#  элементы массива заключаются в двойные кавычки;
# первым элементом указывается исполняемый файл, например, интерпретатор Python; с
# ледом указываются параметры для запуска исполняемого файла:
# CMD ["исполняемый_файл", "аргумент_1", ..., "аргумент_2"] 

# Инструкция CMD в вашем Dockerfile запустит веб-сервер разработки 
# Django-приложения внутри контейнера:
# CMD ["python", "manage.py", "runserver", "0:8000"] 

################################################################################
cd-taski:
	cd "F:\dev\pythonBooks\Контейнерные технологии. Docker и Docker Compose\4. Повторение и примеры\taski-docker\backend"

# Собрать образ на основе докер-файла
build-taski:
	docker build -t taski_backend . 

# build — команда сборки образа по инструкциям из Dockerfile.
# -t taski_backend — задаёт имя образу.
# . — путь до папки с Dockerfile, на основе которого производится сборка. 
# Точка — это текущая директория в терминале.


# запуск контейнера на основе образа из докерфайла
run-taski:
	docker run --name taski_backend_container --rm -p 8000:8000 taski_backend 

#   docker run --name <имя контейнера> --rm -p <порт хотса>:<порт контейнера> <имя образа> 


# Выполните миграции в контейнере taski_backend_container
migrate:
	docker exec taski_backend_container python manage.py migrate

################################################################################

# Устанавливаем gunicorn в образ

# В образе могут быть и другие зависимости — те, что используются вне приложения: 
# например, pip и gunicorn. 
# Такие пакеты нужно устанавливать и настраивать отдельными командами в Dockerfile.
# эта команда должна стоять раньше команды копирования файла requirements.txt
# RUN pip install gunicorn==20.1.0

# Кеширование слоев

# Когда Docker билдит образ, 
# при создании каждого нового слоя он кеширует получившийся набор слоёв. 
# При выполнении следующей инструкции создаётся следующий слой и кешируется следующий набор.
# Если придётся пересобирать образ (например, после внесения изменений в приложение) 
# или требуется создать другой образ, 
# но с тем же набором слоёв, используются подходящие наборы слоёв из кеша. 
# В результате процесс сборки занимает гораздо меньше времени.

################################################################################

# volumes

# При удалении старого контейнера и запуске нового он снова как чистый лист: 
# все данные, накопленные за время работы контейнера, теряются при новом запуске. 
# Это неудобно, а зачастую и недопустимо. 
# Будет плохо, если проект запустится с пустой базой данных: 
# из блога пропадут все записи, а из магазина — все товары и информация о заказах. 

# Docker volume позволяет хранить данные вне контейнера так, 
# чтобы к ним был доступ из контейнера. 

# Внутри контейнера тоже будет файл db.sqlite3, 
# но это будет не хранилище данных, а ретранслятор, 
# который все запросы будет отправлять к файлу, сохранённому снаружи. 
# Однако ни один процесс в контейнере об этом даже знать не будет.
# (см рисунок docker_volume.png)
# Обращаясь к «как бы файлу с данными БД», приложение в контейнере уверено, 
# что оно работает именно с этим файлом, 
# а на самом-то деле все данные хранятся за пределами контейнера. 

# Такие тома можно создавать в любом количестве. 
# Мало того, каждый контейнер может иметь доступ к нескольким томам, 
# а к одному тому могут иметь доступ несколько контейнеров. Many-to-many,как в SQL.

### План создания volumes
# 1. Создать Docker volume с названием sqlite_data.
# 2. Настроить проект Taski так, 
# чтобы файл db.sqlite3 хранился в отдельной папке, 
# которую можно привязать к созданному volume.
# 3. Запустить контейнер бэкенда и при старте указать связь 
# volume sqlite_data с той папкой в контейнере, где хранится db.sqlite3.
# 4. Применить миграции в контейнере; в файле базы данных будут созданы таблицы.
# 5. Проверить, что изменения сохранились в файле за пределами контейнера: 
# открыть файл базы данных на хосте и убедиться, что там созданы таблицы.

volume-create:
	docker volume create sqlite_data 

# По этой команде докер создаст постоянное хранилище данных с названием sqlite_data. 
# При создании тома в терминал будет выведено его имя.

# Теперь надо настроить Django так, чтобы файл db.sqlite3 
# хранился не в папке приложения, а в специальной отдельной директории: 
# дело в том, что с Docker volume можно связать директорию, а не отдельный файл.

# В settings.py замените значение DATABASES на такое:
# DATABASES = {
#     'default': {
#         'ENGINE': 'django.db.backends.sqlite3',
#         'NAME': '/data/db.sqlite3',
#     }
# }

# тобы новые настройки приложения попали в контейнер, пересоберите образ taski_backend
build2:
	docker build -t taski_backend . 

# Вот теперь всё готово, чтобы запустить контейнер с Docker volume:
run-with-volume:
	docker run --name taski_backend_container -p 8000:8000 -v sqlite_data:/data taski_backend

# --name taski_backend_container — присваиваем контейнеру имя;
# -p 8000:8000 — связываем публичный порт контейнера с портом хоста;
# -v — связываем volume с директорией внутри контейнера: имя_volume:директория_в_контейнере.


migrate-again:
	docker exec taski_backend_container python manage.py migrate 

rm-volume:
	docker volume rm sqlite_data

# Если ты подключишь volume к заранее заполненной директории, 
# размещённой в контейнере, содержимое этой директории не будет доступно в volume.
# Внешний том заменяет собой директорию внутри контейнера – 
# поэтому все, что было добавлено в неё на этапе сборки образа, доступно не будет.


################################################################################
### PostgreSQL и Docker network

# Каждый контейнер считает себя отдельным компьютером, 
# поэтому по адресу localhost он обратится к самому себе!

# Чтобы все эти контейнеры работали совместно, надо объединить их в сеть, 
# внутри которой контейнеры смогут обращаться друг к другу не по сетевому адресу, 
# а просто по имени контейнера. 
# Docker умеет создавать такие сети, для этого есть команда docker network. 
# Чтобы подключить контейнер, при старте контейнера указываешь имя сети, 
# и контейнер получает возможность общаться с другими контейнерами, подключёнными к этой же сети.

# На Docker Hub есть готовый образ для PostgreSQL, 
# и запуск контейнера из этого образа даёт некоторые бонусы — например, 
# не требуется вручную устанавливать системные зависимости для PostgreSQL, 
# а база данных настраивается довольно просто.


# Для работы с СУБД PostgreSQL нужно:
# * создать базу данных с определённым именем 
# (ведь на запущенном сервере PostgreSQL может быть несколько баз);
# * установить для базы имя пользователя и пароль, под которыми можно будет подключаться к базе.


# Название базы, логин и пароль пользователя нужно передать в контейнер PostgreSQL, 
# чтобы после запуска в контейнере была создана база с нужными настройками. 
# Для этого есть два варианта:
# - Запустить контейнер, подключиться к серверу базы данных через консоль и вручную 
# создать базу и доступ к ней.
# - Указать имя базы данных, логин и пароль пользователя в переменных окружения контейнера, 
# и тогда при создании контейнера с PostgreSQL будут автоматически созданы база и пользователь, 
# имеющий доступ к этой БД.

# Использование переменных окружения позволяет минимизировать 
# ручную работу по первоначальной настройке БД — вот этот вариант и применим.
# Переменные окружения нужно указать при запуске контейнера; 
# СУБД PostgreSQL при запуске будет ожидать переменные с определёнными названиями:
# POSTGRES_USER — имя пользователя,
# POSTGRES_PASSWORD — пароль пользователя,
# POSTGRES_DB — имя базы данных.

# Переменные окружения можно передать при запуске контейнера, в параметрах команды docker run:
docker-run-postgres:
	docker run -e POSTGRES_PASSWORD=SecretPassword -e POSTGRES_USER=PostgresUser postgres:13.10

# Есть другой вариант: 
# сохранить значения переменных в файл .env — и в параметрах команды docker run 
# передать название этого файла. 

# Этот вариант выглядит предпочтительнее: 
# так будет проще передать одни и те же переменные окружения в разные контейнеры 
# (например, логин и пароль доступа к БД потребуются и в контейнере с PostgreSQL, 
# и в контейнере с Django — там они будут нужны для подключения к БД).

# В корне проекта создайте файл .env

# # Файл .env
# POSTGRES_USER=django_user
# POSTGRES_PASSWORD=mysecretpassword
# POSTGRES_DB=django

# POSTGRES_USER — имя пользователя БД (необязательная переменная, значение по умолчанию — postgres);
# POSTGRES_PASSWORD — пароль пользователя БД (обязательная переменная для создания БД в контейнере);
# POSTGRES_DB — название базы данных (необязательная переменная, по умолчанию совпадает с POSTGRES_USER).

# Таким образом, можно передать в окружение только переменную POSTGRES_PASSWORD — 
# и будет создана БД с названием postgres и пользователем postgres.

# При запуске контейнера имя файла с переменными окружения передают в параметр --env-file:
# Старт контейнера с именем db, переменные окружения в .env, 
# контейнер запустить из образа postgres:13.10
# Эта команда – для демонстрации, запускать ее не надо

docker-run-postgres2:
	docker run --name db --env-file .env postgres:13.10 

# Чтобы при удалении контейнера не потерять информацию, 
# содержащуюся в базе данных, эту информацию следует хранить вне контейнера, 
# в Docker volume на хосте.

# Создайте volume для хранения данных PostgreSQL:
create-pg_data:
	docker volume create pg_data

# В образе PostgreSQL все данные хранятся в директории /var/lib/postgresql/data. 
# Именно эту директорию нужно «перенаправить» на volume за пределами контейнера:
# Старт контейнера ... связать volume pg_data 
# c папкой в контейнере /var/lib/postgresql/data
# Эта команда – для демонстрации, запускать ее не надо.
# docker run ... -v pg_data:/var/lib/postgresql/data  

# Запускаем PostgreSQL в контейнере
# Всё готово, можно запускать контейнер. В итоге команда для запуска будет такой:
# Символ \ в конце строки указывает терминалу, что команда
# продолжится на следующей строке
run-postgres2:
	docker run --name db --env-file .env -v pg_data:/var/lib/postgresql/data postgres:13.10
# Запустить контейнер с именем db, 
# передать в контейнер переменные окружения из файла .env, 
# подключить Docker volume с названием pg_data,
# контейнер создать из образа postgres с тегом 13.10 

# В образе PostgreSQL есть консольный клиент psql, 
# который позволяет отправлять SQL-запросы к базе данных из командной строки.
# Запустите его в отдельном терминале:
exec-postgres2:
	docker exec -it db psql -U django_user -d django 

# exec — выполнить команду в запущенном контейнере;
# -it — запуск в интерактивном режиме;
# db — имя контейнера, в котором нужно выполнить команду;
# psql — имя утилиты, которую нужно запустить в контейнере;
# -U django_user — пользователь, от имени которого psql подключится к базе данных;
# -d django — имя базы данных, к которой нужно подключиться.

# При подключении к базе через psql не нужно указывать пароль пользователя django_user: 
# по умолчанию PostgreSQL доверяет подключениям с того же компьютера, 
# на котором запущен сервер. 
# А в нашем примере мы подключаемся к PostgreSQL из консоли psql, 
# запущенной в том же контейнере (с точки зрения PostgreSQL — на том же компьютере).

# Набор полезных команд в psql
# \help — выводит справку по командам;
# \l — выводит список баз данных на сервере;
# \dt — выводит список таблиц в текущей базе данных.

# Добавьте необходимые переменные в файл .env — пусть в нём хранятся переменные 
# окружения для всех контейнеров. 
# Добавьте файл .env в .gitignore и .dockerignore — 
# файл с паролями не должен попасть в репозиторий и в образ проекта Taski,
#  ведь этот образ будет опубликован на Docker Hub и доступен любому желающему.

# Файл .env
# POSTGRES_USER=django_user
# POSTGRES_PASSWORD=mysecretpassword
# POSTGRES_DB=django
# # Добавляем переменные для Django-проекта:
# DB_HOST=db
# DB_PORT=5432

# DB_HOST — адрес, по которому Django будет соединяться с базой данных. 
# При работе нескольких контейнеров в сети Docker network вместо адреса указывают имя контейнера, 
# где запущен сервер БД, — в нашем случае это контейнер db.
# DB_PORT — порт, по которому Django будет обращаться к базе данных. 
# 5432 — это порт по умолчанию для PostgreSQL.

### Docker network: сеть из контейнеров

# Чтобы Django мог из контейнера обратиться к серверу базы данных в другом контейнере, 
# нужно объединить контейнеры в общую сеть.

# Для управления сетями докер предоставляет команду docker network. 
# Внутри одной сети контейнеры могут обращаться друг к другу просто по именам.

# Сначала в докере создаётся сеть, а затем к сети подключаются контейнеры. 
# Подключить контейнер к сети можно при старте этого контейнера, а можно подключить и контейнер, 
# запущенный до того, как была создана сеть.

# Создадим сеть с именем django-network:
create-network:
	docker network create django-network 

# Контейнер db уже запущен, его можно сразу подключить к докер-сети. Выполните команду:

# Присоединить к сети django-network контейнер db.
connect:
	docker network connect django-network db 

# Контейнер с бэкендом пока не запущен, подключим его к сети прямо при старте. 
# Имя сети, к которой должен подключиться контейнер, указывается как параметр ключа --net.
run3:
	docker run --env-file .env \
			--net django-network \
			--name taski_backend_container \
			-p 8000:8000 taski_backend 

# Если запросы к контейнеру ожидаются только из других контейнеров сети, 
# порты этого контейнера не нужно делать публичными. 
# Контейнер taski_backend_container может обращаться к контейнеру db, 
# при том что у db нет публичных портов, связанных с портами хоста. 
# Контейнеры общаются по сети docker-network, минуя хост.

###############################################################################
### Docker compose: сборка проекта

# Запуск и управление системой контейнеров называют оркестрацией, 
# и для оркестрации есть специальные программы — Kubernetes, Docker Swarm, Podman и Nomad. 
# С их помощью можно подготовить и запустить сеть контейнеров.

### Docker Compose: дирижёр для контейнеров

# Запускать вручную несколько связанных контейнеров неудобно: 
# при каждом старте нужно создавать Docker network, volume, 
# подключать к ним контейнеры — и не запутаться.

# На вашем компьютере установлена утилита Docker Compose — 
# вы её установили вместе с Docker Desktop или отдельной командой в Linux. 
# Это утилита для оркестрации, она-то и поможет запустить несколько контейнеров.

# Все контейнеры и параметры их запуска описывают в файле конфигурации docker-compose.yml. 
# Этот файл чем-то похож на Dockerfile, но если Dockerfile — 
# это рецепт отдельного блюда для повара, то docker-compose.yml — это инструкция, 
# как и в каком порядке подавать готовые блюда на стол.

# Вам предстоит написать файл конфигурации docker-compose.yml — 
# и одной командой запустить все контейнеры проекта Taski.

### Оркестрация сети контейнеров

# Настройки одновременного запуска контейнеров описываются в файле конфигурации,
# в нём задаются описания нужных контейнеров и томов (volume). 
# По умолчанию файл конфигурации должен называться 
# docker-compose.yml. 

# Сеть контейнеров запускается командой 
# docker compose up; 
# при запуске Docker Compose будет искать этот файл в текущей директории.

# Создайте пустой файл docker-compose.yml в корне проекта
# (см docker-compose.yml)

# Все контейнеры, описанные в docker-compose.yml, 
# будут запущены в сети (Docker network). 
# Эту сеть Docker Compose создаст автоматически, описывать её в конфиге необязательно.

### Что внутри docker-compose.yml

# version — версия спецификации файла docker-compose.yml. 
# Обязательный параметр. От версии к версии набор доступных команд меняется, 
# и какие-то команды из новых версий могут не поддерживаться старыми версиями Docker Compose. 
# Узнать, какая версия Docker Compose установлена на компьютере, можно с помощью команды 
# docker compose version
# В документации описано соответствие версий Docker Compose версиям файла docker-compose.yml. 
# Версии Docker Compose 1.10 и выше вполне подойдут для дальнейшей работы.

# volumes — перечень volumes для докера, необязательный параметр. 
# Для каждого имени volume через двоеточие можно указать его подробные настройки. 
# Их можно и не указывать — докер применит настройки по умолчанию.

# services — названия и описания контейнеров, которые должны быть запущены. 
# В листинге описаны три контейнера: db, backend и frontend. 

# Ключи в конфигурации можно указывать в любом порядке. 
# В примере сначала указаны volumes, а потом services: 
# при описании контейнеров удобнее видеть, какие volumes уже созданы.

# Описание каждого контейнера — это YAML-словарь, 
# значения в этом словаре похожи на параметры запуска, которые вы применяли 
# при ручном старте контейнеров. Вот она, автоматизация!

# В описании контейнера объявляется:
# image или build: <address> (одно из двух):
# image — из какого образа создать и запустить контейнер;
# build: <address> — создать образ из докерфайла, который лежит в директории <address>, 
# и запустить контейнер из этого образа.
# volumes — список подключаемых к контейнеру volumes:
#   volumes:
    # - имя_volume:директория_контейнера
   
# Другой распространённый вариант — просто указать директорию контейнера, для которой будет создан volume:
#   volumes:
    # - директория_контейнера
   
# Такой volume называется анонимным volume (у него не будет имени), 
# его не нужно описывать в общем блоке volumes.
# Остальные способы создания volumes можно посмотреть в документации.

# env_file указывает один или несколько файлов с переменными окружения для контейнера.
# depends_on — список контейнеров, которые должны быть запущены перед запуском описываемого контейнера. 
# Значение ключа depends_on — список: иногда запускаемый контейнер зависит не от одного, 
# а от нескольких других контейнеров. 
# В листинге сказано, что контейнер backend должен быть запущен после контейнера db: 
# при старте Django-приложения база данных должна быть уже доступна.

# Дополнительно в depends_on можно указать состояние предыдущего контейнера, 
# при котором можно запустить текущий контейнер, — это описано в документации.

### Поднимаем сеть контейнеров: docker compose up

# Запустите весь оркестр — в терминале в папке с docker-compose.yml выполните команду:
up:
	docker compose up 

# Есть устаревший вариант запуска Docker Compose: docker-compose вместо docker compose. 
# Он больше не поддерживается, но может встречаться на уже настроенных серверах. 
# Эти команды работают одинаково.

# По команде docker compose up Docker Compose: 
# получит готовые образы, указанные в image,
# соберёт все образы, указанные в build,
# запустит все контейнеры, описанные в конфиге.


# Перейдите в директорию, где лежит файл docker-compose.yml, и выполните миграции:
exec4:
	docker compose exec backend python manage.py migrate 

# Для связи Django c БД не требуется явным образом указывать порты: 
# контейнер бэкенда обращается к контейнеру с базой через внутреннюю сеть докера. 
# Чтобы обратиться из одного контейнера в другой, их порты не нужно пробрасывать на хост.

###############################################################################

### Docker-compose: Nginx и статика

# Настроим точку входа для пользователей — гейтвей. 
# Это приложение, прокси-сервер, которое будет получать все запросы и возвращать ответы. 
# Пользователь будет общаться только с этим приложением, 
# а gateway часть запросов будет обрабатывать сам, а часть будет передавать другим приложениям. 
# В Taski роль gateway будет играть Nginx.

### Врата в докер: контейнер и конфиг для Nginx
# Подготовьте запуск контейнера с Nginx — создайте в корне проекта папку gateway/ с двумя файлами:
# Dockerfile — для создания образа Nginx с нужными настройками;
# nginx.conf — для конфигурации сервера Nginx.

# Скопируйте в файл nginx.conf конфигурацию для сервера Nginx:
# Файл nginx.conf
# server {
#   # Указание серверу: слушай порт контейнера 80
#   listen 80;

#   # Запросы по адресам /api/... перенаправляй в контейнер backend
#   location /api/ {
#     # Полученный запрос отправь по протоколу http в контейнер backend
#     # на порт 8000 — именно его слушает Gunicorn
#     proxy_pass http://backend:8000/api/;
#   }
#   # Так же поступай и с запросами к адресам /admin/...
#   location /admin/ {
#     proxy_pass http://backend:8000/admin/;
#   }

#   # По запросу к главной странице проекта должно открыться фронтенд-приложение.
#   # Все его файлы должны лежать в приложении со статикой 
#   location / {
#     # Всю статику будем искать в папке /staticfiles/.
#     # В ней будет доступна статика фронтенда и статика бэкенда.
#     # Инструкция alias указывает, где лежат
#     # статические файлы, которые должен раздавать Nginx
#     alias /staticfiles/;
#     # Если в запросе не указано, какой файл вернуть, 
#     # возвращай файл index.html — он есть в папке со статикой
#     index index.html;
#   }
# }

# Запросы к API и к админке проекта будут переадресованы в Django, 
# а все остальные запросы, включая и запрос к главной странице, 
# Nginx будет обрабатывать самостоятельно, возвращая файлы из директории /staticfiles/. 
# При запросе к главной странице Nginx вернёт файл index.html 
# (эта инструкция есть в конце конфига). 
# Файл index.html содержит ссылки на остальные файлы, необходимые для работы SPA. 
# Когда браузер получит и прочтёт файл index.html, он отправит дополнительные запросы, 
# чтобы получить эти файлы. Nginx будет искать эти файлы тоже в директории /staticfiles/.

# Dockefile для образа nginx будет очень коротким: 
# В качестве базового слоя взять с Docker Hub готовый образ nginx:1.22.1.
# Скопировать в создаваемый образ конфиг-файл nginx.conf.
# Сервер Nginx ожидает найти файл с настройками по адресу 
# /etc/nginx/templates/default.conf.template, вот туда его и скопируем из директории gateway/.

# FROM nginx:1.22.1
# COPY nginx.conf /etc/nginx/templates/default.conf.template 

# Именно так в документации и рекомендовано добавлять файл конфигурации в образ nginx.

# Чтобы контейнер с Nginx появился в «оркестре»,
#  включим описание контейнера в файл docker-compose.yml. 
# А чтобы контейнер с Nginx мог слушать запросы с хоста — нужно назначить 
# соответствие портов контейнера портам хоста, «пробросить порты». 
# Проброс настраивается с помощью ключа ports в описании контейнера в docker-compose.yml.

# # Добавляем новый контейнер: gateway.
#   gateway:
#     # Сбилдить и запустить образ, 
#     # описанный в Dockerfile в папке gateway
#     build: ./gateway/
#     # Ключ ports устанавливает
#     # перенаправление всех запросов с порта 8000 хоста
#     # на порт 80 контейнера.
#     ports:
#       - 8000:80 
# (см docker-compose.yml)


# docker compose up 
# Откройте в браузере страницу http://localhost:8000/admin/.

# Но как так? Я захожу на http://localhost:8000/admin/, а в ошибке показан адрес http://backend:8000?

# Когда Nginx из своего контейнера обращается к другому контейнеру, 
# он использует имя контейнера в качестве доменного имени. 
# Так, к контейнеру backend Nginx обращается по адресу http://backend:8000. 
# Из-за этого Django-проект будет считать, что запрос отправлен не на http://localhost:8000, 
# как указано в адресной строке браузера, а на http://backend:8000. 
# Это может привести к неправильному формированию ссылок. 
# Чтобы избежать этой проблемы, добавь инструкцию замены заголовка Host в nginx.conf.

# server {
#   listen 80;

#   # Запросы по адресам /api/... перенаправляй в контейнер backend
#   location /api/ {
#     # Это и есть нужная строка:
#     # при перенаправлении запроса в контейнер backend
#     # подменить адрес "backend" в заголовке запроса 
#     # на тот адрес, который пользователь ввёл в браузере
#     proxy_set_header Host $http_host;
#     proxy_pass http://backend:8000/api/;
#   }
#   location /admin/ {
#     # И в этом блоке то же самое:
#     proxy_set_header Host $http_host;
#     proxy_pass http://backend:8000/admin/;
#   }

#   location / {
#     alias /staticfiles/;
#     index index.html;
#   }
# } 
# 
# Остановите Docker Compose с помощью Ctrl+C и вновь запустите его:


# Команды, объединённые символами &&, выполняются последовательно;
# вторая команда выполнится, только если первая выполнилась успешно.
# Ключ --build для docker compose up означает,
# что перед запуском нужно пересобрать образы
up-buil:
	docker compose stop && docker compose up --build 

# Остановите Docker Compose при помощи Ctrl+C.

### Делимся файлами: Docker volume для нескольких контейнеров

# Статические файлы в проекте сейчас хранятся в двух контейнерах: 
# в контейнере backend в директории /app/collected_static/,
# в контейнере frontend в директории /app/build/.
# Нужно настроить контейнеры так, чтобы статика фронтенда и бэкенда стала доступна для Nginx.

# Когда мы проектировали архитектуру, то придумали такое решение: 
# создадим volume для статики и дадим к нему доступ всем трём контейнерам. 
# Контейнеры frontend и backend будут сохранять туда свою статику, 
# а Nginx — раздавать её. Получится что-то вроде «облачного хранилища», 
# к которому имеют доступ несколько пользователей.

# Вот так будет выглядеть структура папок в volume static:
# static # Корень volume, здесь файлы статики от frontend
# ├── asset-manifest.json
# ├── favicon.ico
# ├── index.html
# ├── logo192.png
# ├── logo512.png
# ├── manifest.json
# ├── robots.txt
# └── static # А в этой папке — файлы и от frontend, и от backend
#     ├── admin/ # статика админки Django 
#     ├── css/ # CSS фронтенда
#     ├── js/ # JS фронтенда
#     └── rest_framework/ # Статика Django REST Framework 

### Статика бэкенд-приложения

# Начнём со статики Django. При запуске контейнера backend необходимо выполнить четыре задачи:
# запустить сервер Gunicorn,
# собрать статику,
# скопировать её в backend_static/,
# выполнить миграции.

# Миграции уже выполнены, запуск Gunicorn тоже выполняется 
# — его старт описан в инструкции CMD в Dockerfile образа бэкенд-приложения. 
# Остальные команды запустить через Dockerfile не удастся 
# — инструкция CMD в докерфайле может быть только одна, 
# а копировать файлы на volume можно только при запущенном контейнере.

# Сбор статики и копирование файлов выполним вручную после запуска контейнера 
# — прямо из консоли, через docker exeс.

# Для начала в проекте Taski настройте сбор статики в папку collected_static/. 
# В файле settings.py проверьте значение константы STATIC_URL и добавьте константу STATIC_ROOT:
# # При планировании архитектуры было решено,
# # что статические файлы Django должны быть доступны по адресу /static/
# STATIC_URL = '/static/'
# # Указываем корневую директорию для сборки статических файлов;
# # в контейнере это будет /app/collected_static
# STATIC_ROOT = BASE_DIR / 'collected_static'
# # Теперь при вызове команды python manage.py collectstatic
# # Django будет копировать все статические файлы в директорию collected_static 


# Теперь создайте volume static и подключите его к директории /backend_static/ контейнера backend:

# volumes:
#   pg_data:
#   # Новый volume — для статических файлов
#   static:

# (см docker compose)

# При старте сети к контейнерам backend и gateway подключился volume static. 
# Выполните команду сборки статики. 
# После этого выполните команду копирования собранных файлов в /backend_static/static/ — 
# перенесите файлы не в /backend_static/, а во вложенную папку: 
# так адреса файлов для Nginx совпадут с адресами статических файлов, которые ожидает Django-проект.


# Собрать статику Django
collectstatic3:
	docker compose exec backend python manage.py collectstatic
# Статика приложения в контейнере backend 
# будет собрана в директорию /app/collected_static/.

# Теперь из этой директории копируем статику в /backend_static/static/;
# эта статика попадёт на volume static в папку /static/:
cp4:
	docker compose exec backend cp -r /app/collected_static/. /backend_static/static/ 


### Статика фронтенда

# При запуске контейнера frontend в нём выполняется инструкция CMD, 
# в которой описан запуск встроенного сервера, раздающего статику. 
# Но теперь статикой займётся Nginx, так что запускать сервер фронтенда не требуется. 

# Всё, что теперь нужно от контейнера frontend, — это просто собрать свои файлы статики. 
# Текущая инструкция CMD в докерфайле фронтенда уже не нужна, 
# и её можно заменить на команду копирования статики в директорию /frontend_static/.

# Для переопределения инструкции CMD не обязательно изменять докерфайл и пересобирать образ: 
# в docker-compose.yml в описании контейнера можно применить ключ command.
# command — аналог инструкции CMD в докерфайле: 
# здесь пишется команда, которая должна быть выполнена после запуска контейнера. 
# Команда, указанная под ключом command, переопределяет инструкцию CMD в докерфайле, заменяет её.

# Таким образом, в docker-compose.yml в описание контейнера frontend нужно внести пару изменений:
# объявить связь директории /frontend_static/ c volume static 
# (при этом директория будет создана автоматически);
# добавить ключ command и выполнить команду копирования файлов: cp -r /app/build/. /frontend_static/.
# Внесите эти изменения в docker-compose.yml самостоятельно, 
# а если что-то пойдёт не так — подсмотрите готовое решение.










































